{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorge-martinez-gil/colab-notebooks/blob/main/GraphCodeBERT%2BFeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "main-code"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Runtime/Resource benchmarking for:\n",
        "- Baseline: GraphCodeBERT classifier\n",
        "- Ours: GraphCodeBERT + additional scalar feature\n",
        "\n",
        "No wandb. Works on old/new transformers.\n",
        "Dataset JSON fields: code1, code2, score (0/1), output (float)\n",
        "\n",
        "Author: Jorge Martinez-Gil\n",
        "\"\"\"\n",
        "\n",
        "# ⚠️ Requirement: Enable GPU\n",
        "# To run this notebook efficiently, you must enable GPU acceleration:\n",
        "# 1. Go to **Runtime** > **Change runtime type**.\n",
        "# 2. Select **T4 GPU** under Hardware accelerator.\n",
        "# 3. Click **Save**.\n",
        "\n",
        "# ---- Disable external loggers (esp. wandb) ----\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
        "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"true\"\n",
        "\n",
        "import time, json, random\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Dict, Any\n",
        "\n",
        "import os, urllib.request\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModel,\n",
        "    Trainer, TrainingArguments\n",
        ")\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "# ----------------------------\n",
        "# Config\n",
        "# ----------------------------\n",
        "MODEL_NAME = \"microsoft/graphcodebert-base\"\n",
        "DATASET_URL = \"https://www.jorgemar.com/data/data2.json\"\n",
        "DATASET_PATH = \"data2.json\"\n",
        "MAX_LENGTH = 512\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 3\n",
        "EVAL_STEPS = 500          # used only if the runtime supports step-based eval\n",
        "SAVE_STEPS = 500          # used only if the runtime supports step-based save\n",
        "WARMUP_STEPS = 500\n",
        "WEIGHT_DECAY = 0.01\n",
        "SEED = 42\n",
        "LAT_SAMPLES = 64          # samples for latency timing\n",
        "\n",
        "\n",
        "# Download dataset if not present\n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    print(f\"Downloading dataset from {DATASET_URL}\")\n",
        "    urllib.request.urlretrieve(DATASET_URL, DATASET_PATH)\n",
        "\n",
        "# ----------------------------\n",
        "# Utils\n",
        "# ----------------------------\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def count_params(model: nn.Module) -> int:\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "def gpu_name() -> str:\n",
        "    return torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
        "\n",
        "def reset_peak_mem():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.reset_peak_memory_stats(0)\n",
        "\n",
        "def peak_gpu_gb() -> float:\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.synchronize()\n",
        "        alloc = torch.cuda.max_memory_allocated(0) / (1024 ** 3)\n",
        "        reserv = torch.cuda.max_memory_reserved(0) / (1024 ** 3)\n",
        "        return max(alloc, reserv)\n",
        "    return 0.0\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    # Works with both older and newer HF EvalPrediction objects\n",
        "    if isinstance(eval_pred, (tuple, list)):\n",
        "        preds, labels = eval_pred\n",
        "    else:\n",
        "        preds, labels = eval_pred.predictions, eval_pred.label_ids\n",
        "    preds = np.argmax(preds, axis=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary', zero_division=0)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "# ----------------------------\n",
        "# Dataset\n",
        "# ----------------------------\n",
        "class CodePairDataset(Dataset):\n",
        "    def __init__(self, file_path: str, tokenizer: AutoTokenizer, max_length: int = 512, use_feature: bool = True):\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            self.data = json.load(f)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.use_feature = use_feature\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
        "        item = self.data[idx]\n",
        "        enc = self.tokenizer(\n",
        "            text=item[\"code1\"],\n",
        "            text_pair=item[\"code2\"],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        enc = {k: v.squeeze(0) for k, v in enc.items()}  # remove batch dim\n",
        "        enc[\"labels\"] = torch.tensor(int(item[\"score\"]), dtype=torch.long)\n",
        "        if self.use_feature:\n",
        "            enc[\"output_feature\"] = torch.tensor(float(item[\"output\"]), dtype=torch.float)\n",
        "        else:\n",
        "            enc[\"output_feature\"] = torch.tensor(0.0, dtype=torch.float)  # placeholder for baseline\n",
        "        return enc\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "# ----------------------------\n",
        "# Models\n",
        "# ----------------------------\n",
        "class GCBaseline(nn.Module):\n",
        "    \"\"\"Baseline GraphCodeBERT classifier using CLS.\"\"\"\n",
        "    def __init__(self, num_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.encoder = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        self.dropout = nn.Dropout(getattr(self.encoder.config, \"hidden_dropout_prob\", 0.1))\n",
        "        self.classifier = nn.Linear(self.encoder.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None, output_feature=None):\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls = outputs.last_hidden_state[:, 0, :]\n",
        "        x = self.dropout(cls)\n",
        "        logits = self.classifier(x)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = nn.CrossEntropyLoss()(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "        return SequenceClassifierOutput(loss=loss, logits=logits)\n",
        "\n",
        "class GCOurs(nn.Module):\n",
        "    \"\"\"GraphCodeBERT + scalar feature projected and concatenated to CLS.\"\"\"\n",
        "    def __init__(self, num_labels: int = 2, feature_dim: int = 1):\n",
        "        super().__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.encoder = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        self.dropout = nn.Dropout(getattr(self.encoder.config, \"hidden_dropout_prob\", 0.1))\n",
        "        self.feature_proj = nn.Linear(feature_dim, self.encoder.config.hidden_size)\n",
        "        self.classifier = nn.Linear(self.encoder.config.hidden_size * 2, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None, output_feature=None):\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls = outputs.last_hidden_state[:, 0, :]\n",
        "        feat = self.feature_proj(output_feature.unsqueeze(-1))\n",
        "        x = torch.cat([cls, feat], dim=1)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.classifier(x)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = nn.CrossEntropyLoss()(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "        return SequenceClassifierOutput(loss=loss, logits=logits)\n",
        "\n",
        "# ----------------------------\n",
        "# Training / Eval Runner\n",
        "# ----------------------------\n",
        "@dataclass\n",
        "class RunResult:\n",
        "    variant: str\n",
        "    params_m: float\n",
        "    train_hours: float\n",
        "    latency_ms: float\n",
        "    gpu: str\n",
        "    peak_mem_gb: float\n",
        "    batch_size: int\n",
        "    seq_len: int\n",
        "    f1: Optional[float] = None\n",
        "    precision: Optional[float] = None\n",
        "    recall: Optional[float] = None\n",
        "    accuracy: Optional[float] = None\n",
        "\n",
        "def make_splits(dataset: Dataset, train_ratio=0.8):\n",
        "    n = len(dataset)\n",
        "    n_train = int(train_ratio * n)\n",
        "    n_val = (n - n_train) // 2\n",
        "    n_test = n - n_train - n_val\n",
        "    return random_split(dataset, [n_train, n_val, n_test], generator=torch.Generator().manual_seed(SEED))\n",
        "\n",
        "def measure_latency(model: nn.Module, test_dataset: Dataset, lat_samples: int = 64) -> float:\n",
        "    dl = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Warmup a few steps\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(dl):\n",
        "            batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
        "            _ = model(**{k: v for k, v in batch.items() if k in (\"input_ids\", \"attention_mask\", \"labels\", \"output_feature\")})\n",
        "            if i >= 3: break\n",
        "\n",
        "    if torch.cuda.is_available(): torch.cuda.synchronize()\n",
        "    t1 = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        i = 0\n",
        "        for batch in dl:\n",
        "            batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
        "            _ = model(**{k: v for k, v in batch.items() if k in (\"input_ids\", \"attention_mask\", \"labels\", \"output_feature\")})\n",
        "            i += 1\n",
        "            if i >= min(lat_samples, len(test_dataset)): break\n",
        "    if torch.cuda.is_available(): torch.cuda.synchronize()\n",
        "    t2 = time.perf_counter()\n",
        "    return ((t2 - t1) / max(1, i)) * 1000.0\n",
        "\n",
        "def build_training_args(variant_name: str) -> TrainingArguments:\n",
        "    \"\"\"\n",
        "    Version-robust TrainingArguments:\n",
        "    - Try new-style args first (eval/save strategies).\n",
        "    - If unsupported, fall back to minimal args.\n",
        "    \"\"\"\n",
        "    base = dict(\n",
        "        output_dir=f\"./results_{variant_name.replace(' ', '_').lower()}\",\n",
        "        num_train_epochs=EPOCHS,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        learning_rate=5e-5,\n",
        "        warmup_steps=WARMUP_STEPS,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "        logging_dir=f\"./logs_{variant_name.replace(' ', '_').lower()}\",\n",
        "        seed=SEED,\n",
        "    )\n",
        "    # Try modern API\n",
        "    try:\n",
        "        return TrainingArguments(\n",
        "            evaluation_strategy=\"steps\",\n",
        "            eval_steps=EVAL_STEPS,\n",
        "            save_strategy=\"steps\",\n",
        "            save_steps=SAVE_STEPS,\n",
        "            report_to=[\"none\"],  # no wandb/tensorboard\n",
        "            **base,\n",
        "        )\n",
        "    except TypeError:\n",
        "        # Older API fallback\n",
        "        return TrainingArguments(**base)\n",
        "\n",
        "def run_variant(variant_name: str, model: nn.Module, dataset: CodePairDataset) -> RunResult:\n",
        "    set_seed(SEED)\n",
        "    train_ds, val_ds, test_ds = make_splits(dataset)\n",
        "    training_args = build_training_args(variant_name)\n",
        "\n",
        "    # Try to build Trainer with eval hooks; if it fails, fallback to train-only\n",
        "    try:\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_ds,\n",
        "            eval_dataset=val_ds,\n",
        "            compute_metrics=compute_metrics,\n",
        "        )\n",
        "        supports_eval = True\n",
        "    except TypeError:\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_ds,\n",
        "        )\n",
        "        supports_eval = False\n",
        "\n",
        "    # ---- Train & time\n",
        "    reset_peak_mem()\n",
        "    t0 = time.perf_counter()\n",
        "    trainer.train()\n",
        "    train_seconds = time.perf_counter() - t0\n",
        "    train_hours = train_seconds / 3600.0\n",
        "\n",
        "    # ---- Evaluate (test)\n",
        "    if supports_eval:\n",
        "        _ = trainer.evaluate(eval_dataset=val_ds)  # optional val metrics\n",
        "        test_metrics = trainer.evaluate(eval_dataset=test_ds)\n",
        "        f1 = float(test_metrics.get(\"eval_f1\", float(\"nan\")))\n",
        "        prec = float(test_metrics.get(\"eval_precision\", float(\"nan\")))\n",
        "        rec  = float(test_metrics.get(\"eval_recall\", float(\"nan\")))\n",
        "        acc  = float(test_metrics.get(\"eval_accuracy\", float(\"nan\")))\n",
        "    else:\n",
        "        # Manual evaluation for older versions\n",
        "        preds, labels = [], []\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device); model.eval()\n",
        "        dl = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
        "        with torch.no_grad():\n",
        "            for batch in dl:\n",
        "                b = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
        "                out = model(**{k: v for k, v in b.items() if k in (\"input_ids\", \"attention_mask\", \"labels\", \"output_feature\")})\n",
        "                pred = int(out.logits.argmax(dim=-1).detach().cpu().item())\n",
        "                label = int(b[\"labels\"].item())\n",
        "                preds.append(pred); labels.append(label)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary', zero_division=0)\n",
        "        acc = accuracy_score(labels, preds)\n",
        "        prec = float(precision); rec = float(recall)\n",
        "\n",
        "    # ---- Resource stats\n",
        "    peak_mem = peak_gpu_gb()\n",
        "    params_m = count_params(model) / 1e6\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    latency_ms = measure_latency(model, test_ds, LAT_SAMPLES)\n",
        "\n",
        "    return RunResult(\n",
        "        variant=variant_name,\n",
        "        params_m=params_m,\n",
        "        train_hours=train_hours,\n",
        "        latency_ms=latency_ms,\n",
        "        gpu=gpu_name(),\n",
        "        peak_mem_gb=peak_mem,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seq_len=MAX_LENGTH,\n",
        "        f1=f1, precision=prec, recall=rec, accuracy=acc\n",
        "    )\n",
        "\n",
        "# ----------------------------\n",
        "# Printing helpers\n",
        "# ----------------------------\n",
        "def print_summary_table(results):\n",
        "    print(\"\\n=== RUNTIME/RESOURCE SUMMARY ===\")\n",
        "    header = f\"{'Variant':40s} {'Params(M)':>10s} {'Train(h)':>10s} {'Infer(ms)':>10s} {'GPU':>12s} {'PeakMem(GB)':>12s} {'Batch':>7s} {'Seq':>5s}\"\n",
        "    print(header)\n",
        "    print(\"-\" * len(header))\n",
        "    for r in results:\n",
        "        print(f\"{r.variant:40s} {r.params_m:10.2f} {r.train_hours:10.2f} {r.latency_ms:10.2f} {r.gpu:12s} {r.peak_mem_gb:12.2f} {r.batch_size:7d} {r.seq_len:5d}\")\n",
        "\n",
        "def print_metrics_table(results):\n",
        "    print(\"\\n=== TEST METRICS (for context) ===\")\n",
        "    header = f\"{'Variant':40s} {'F1':>8s} {'Prec':>8s} {'Rec':>8s} {'Acc':>8s}\"\n",
        "    print(header)\n",
        "    print(\"-\" * len(header))\n",
        "    for r in results:\n",
        "        print(f\"{r.variant:40s} {r.f1 if r.f1 is not None else float('nan'):8.4f} \"\n",
        "              f\"{r.precision if r.precision is not None else float('nan'):8.4f} \"\n",
        "              f\"{r.recall if r.recall is not None else float('nan'):8.4f} \"\n",
        "              f\"{r.accuracy if r.accuracy is not None else float('nan'):8.4f}\")\n",
        "\n",
        "def print_latex_table(results):\n",
        "    print(\"\\n=== LaTeX (copy/paste) ===\")\n",
        "    print(r\"\\begin{table}[t]\")\n",
        "    print(r\"\\centering\")\n",
        "    print(r\"\\caption{Training and inference resources on NVIDIA A100 (same setup for all rows).}\")\n",
        "    print(r\"\\label{tab:runtime}\")\n",
        "    print(r\"\\setlength{\\tabcolsep}{6pt}\")\n",
        "    print(r\"\\renewcommand{\\arraystretch}{1.2}\")\n",
        "    print(r\"\\begin{tabular}{l\"\n",
        "          r\"                S[table-format=3.2]\"\n",
        "          r\"                S[table-format=2.2]\"\n",
        "          r\"                S[table-format=2.2]\"\n",
        "          r\"                l\"\n",
        "          r\"                S[table-format=2.2]\"\n",
        "          r\"                S[table-format=2.0]\"\n",
        "          r\"                S[table-format=3.0]}\")\n",
        "    print(r\"\\toprule\")\n",
        "    print(r\"{Variant} & {Params (M)} & {Train (h)} & {Infer (ms)} & {GPU} & {Peak Mem (GB)} & {Batch} & {Seq} \\\\\")\n",
        "    print(r\"\\midrule\")\n",
        "    for r in results:\n",
        "        print(fr\"{r.variant} &  {r.params_m:.2f} & {r.train_hours:.2f} & {r.latency_ms:.2f} & {r.gpu} & {r.peak_mem_gb:.2f} & {r.batch_size} & {r.seq_len} \\\\\")\n",
        "    print(r\"\\bottomrule\")\n",
        "    print(r\"\\end{tabular}\")\n",
        "    print(r\"\\vspace{2mm}\")\n",
        "    print(r\"\\footnotesize\")\n",
        "    print(fr\"\\textbf{{Setup:}} PyTorch \\texttt{{{torch.__version__}}}, CUDA \\texttt{{{torch.version.cuda}}}. \"\n",
        "          fr\"Seed = {SEED}, epochs = {EPOCHS}, warmup = {WARMUP_STEPS}, weight decay = {WEIGHT_DECAY}, eval/save steps = {EVAL_STEPS}.\")\n",
        "    print(r\"\\end{table}\")\n",
        "\n",
        "# ----------------------------\n",
        "# Main\n",
        "# ----------------------------\n",
        "def main():\n",
        "    if not os.path.exists(DATASET_PATH):\n",
        "        raise FileNotFoundError(f\"Dataset not found at {DATASET_PATH}.\")\n",
        "    set_seed(SEED)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    ds_baseline = CodePairDataset(DATASET_PATH, tokenizer, MAX_LENGTH, use_feature=False)\n",
        "    ds_ours = CodePairDataset(DATASET_PATH, tokenizer, MAX_LENGTH, use_feature=True)\n",
        "\n",
        "    baseline_model = GCBaseline(num_labels=2)\n",
        "    ours_model = GCOurs(num_labels=2, feature_dim=1)\n",
        "\n",
        "    res_baseline = run_variant(\"GraphCodeBERT (baseline)\", baseline_model, ds_baseline)\n",
        "    res_ours = run_variant(\"Ours: + additional feature\", ours_model, ds_ours)\n",
        "\n",
        "    results = [res_baseline, res_ours]\n",
        "\n",
        "    print_summary_table(results)\n",
        "    print_metrics_table(results)\n",
        "    print_latex_table(results)\n",
        "    print(\"\\nTip: keep batch size and seq length identical across rows; mention any param/memory delta in the caption.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "GraphCodeBERT+Features.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}